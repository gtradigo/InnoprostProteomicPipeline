{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gtradigo/InnoprostProteomicPipeline/blob/main/pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu6o6ZUJEBLr"
      },
      "source": [
        "# Pipeline for clinical and proteomic data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TQXb4M2Dh9q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "from scipy.stats import reciprocal, uniform\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, f1_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_selection import SelectKBest, chi2, RFE, SelectFromModel\n",
        "from sklearn.decomposition import PCA\n",
        "%matplotlib inline\n",
        "from matplotlib.pylab import rcParams\n",
        "rcParams['figure.figsize']= 18, 8\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "np.random.seed(123456)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qg3k6WSN06dh"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xchqQqWgD6gR"
      },
      "source": [
        "Import the biological dataset containing peptide data. Data will be normalized and analyzed through the pipeline phases.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SB_cWStAD1ce"
      },
      "outputs": [],
      "source": [
        "# load dataset\n",
        "data = pd.read_excel('/content/drive/...', sheet_name = '...')\n",
        "# delete unnamed columns\n",
        "data = data.loc[:, ~data.columns.str.contains('^Unnamed')]\n",
        "# data preview\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJJGLVakFLNi"
      },
      "source": [
        "## Data preprocessing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print column names\n",
        "data.columns"
      ],
      "metadata": {
        "id": "zjI4xViSNpP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etXGBd18FQM1"
      },
      "outputs": [],
      "source": [
        "# delete unwanted columns\n",
        "data = data.drop(['Name','Gleason'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okMbHHUUFXCO"
      },
      "source": [
        "Optionally impute missing values\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bj7rKm0xFghp"
      },
      "outputs": [],
      "source": [
        "# replace not a number with zeroes\n",
        "data = data.replace(np.nan,0.0)\n",
        "# replace infinitive values with zeroes\n",
        "data = data.replace(np.inf,0.0)\n",
        "# report missing values\n",
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xidfbZx4FpYm"
      },
      "source": [
        "Optionally delete row not having the class variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2WPOmcyFsHD"
      },
      "outputs": [],
      "source": [
        "class_column = 'COLUMN COINTAING CLASS'\n",
        "# delete rows without target value\n",
        "data = data.drop(data[data[class_column] == 0.0].index, axis=0)\n",
        "data = data.reset_index()\n",
        "data = data.drop(['index'], axis = 1)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now uniform back all zeroes to \"not a number\" values before value imputation"
      ],
      "metadata": {
        "id": "6VpY4xSuuARJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMMzsRRBFwS5"
      },
      "outputs": [],
      "source": [
        "data = data.replace(0.0, np.nan)\n",
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOpGDP9xF9_A"
      },
      "source": [
        "## Missing values imputation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1VfLZlXF_Qc"
      },
      "outputs": [],
      "source": [
        "for column in data:\n",
        "  data[column] = data[column].fillna(data[column].mean())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# count how many rows are in each target\n",
        "data[class_column].value_counts()"
      ],
      "metadata": {
        "id": "FaT5ptnDXCZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOS-0cnEGUMM"
      },
      "source": [
        "Let's binarize the class variable: 0 for the first one, 1 for the second one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ta7t82vPGXjo"
      },
      "outputs": [],
      "source": [
        "data[class_column].loc[data[class_column] == 'FIRST_CLASS_LABEL' ] = 0\n",
        "data[class_column].loc[data[class_column] == 'SECOND_CLASS_LABEL' ] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqlWu4M5G1RD"
      },
      "outputs": [],
      "source": [
        "# output variable\n",
        "Y = data[class_column]\n",
        "# training data\n",
        "X_1 = data.drop([class_column], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib1CElejG5N0"
      },
      "source": [
        "# Feature selection\n",
        "\n",
        "Select a subset of variables significant for the analysis phases, by using several (and optional) Machine Learning tools:\n",
        "\n",
        "* **Pearson correlation**\n",
        "* **Chi-square test**\n",
        "* **RFE**\n",
        "* **Logistic regression**\n",
        "* **Random Forest**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlrd6UQVHUzo"
      },
      "outputs": [],
      "source": [
        "# convert output to float type\n",
        "Y = Y.astype(float)\n",
        "# max number of features\n",
        "num_feats = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhoKHfFxHjzl"
      },
      "source": [
        "#  Pearson correlation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_WoaHO8Hqb8"
      },
      "outputs": [],
      "source": [
        "X_scaled = MinMaxScaler().fit_transform(X_1)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns = X_1.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RVGgKKyHvuy"
      },
      "outputs": [],
      "source": [
        "def cor_selector(X, Y, num_feats):\n",
        "  cor_list = []\n",
        "  feature_name = X.columns.tolist()\n",
        "\n",
        "  for i in X.columns.tolist():\n",
        "    cor = np.corrcoef(X[i], Y)[0, 1]\n",
        "    cor_list.append(cor)\n",
        "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
        "    cor_feature = X.iloc[:, np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()\n",
        "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
        "\n",
        "  return cor_support, cor_feature\n",
        "\n",
        "cor_support, cor_feature = cor_selector(X_scaled, Y, num_feats)\n",
        "print(str(len(cor_feature)), 'selected features')\n",
        "print(cor_feature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL3hRdvCIE0e"
      },
      "source": [
        "# Chi square\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oPutg-oIOPF"
      },
      "outputs": [],
      "source": [
        "chi_selector = SelectKBest(chi2, k = num_feats)\n",
        "chi_selector.fit(X_scaled, Y)\n",
        "chi_support = chi_selector.get_support()\n",
        "chi_feature = X_scaled.loc[:,chi_support].columns.tolist()\n",
        "print(str(len(chi_feature)), 'selected features')\n",
        "print(chi_feature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2kaWZepIVrP"
      },
      "source": [
        "# RFE - Recursive Feature Elimination\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw1LScplId6B"
      },
      "outputs": [],
      "source": [
        "rfe_selector = RFE(estimator = LogisticRegression(), n_features_to_select = num_feats, step = 5, verbose = 5)\n",
        "rfe_selector.fit(X_scaled, Y)\n",
        "rfe_support = rfe_selector.get_support()\n",
        "rfe_feature = X_scaled.loc[:,rfe_support].columns.tolist()\n",
        "print(str(len(rfe_feature)), 'selected features')\n",
        "print(rfe_feature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51hU81iTIhu9"
      },
      "source": [
        "# Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcC8349cJPo3"
      },
      "outputs": [],
      "source": [
        "embedded_lr_selector = SelectFromModel(LogisticRegression(penalty = \"l1\", solver = 'liblinear'), max_features = num_feats)\n",
        "embedded_lr_selector.fit(X_scaled, Y)\n",
        "embedded_lr_support = embedded_lr_selector.get_support()\n",
        "embedded_lr_feature = X_scaled.loc[:,embedded_lr_support].columns.tolist()\n",
        "print(str(len(embedded_lr_feature)), 'selected features')\n",
        "print(embedded_lr_feature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4Y9_vlEJQjQ"
      },
      "source": [
        "# Random Forest\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36-D-3XWKLHQ"
      },
      "outputs": [],
      "source": [
        "embedded_rf_selector = SelectFromModel(RandomForestClassifier(30), max_features = num_feats)\n",
        "embedded_rf_selector.fit(X_scaled, Y)\n",
        "embedded_rf_support = embedded_rf_selector.get_support()\n",
        "embedded_rf_feature = X_scaled.loc[:,embedded_rf_support].columns.tolist()\n",
        "print(str(len(embedded_rf_feature)), 'selected features')\n",
        "print(embedded_rf_feature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg-yd5ppKTKz"
      },
      "source": [
        "# Feature selection table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMVZebXlKXup"
      },
      "outputs": [],
      "source": [
        "feature_name= X_scaled.columns\n",
        "\n",
        "feature_selection_df = pd.DataFrame({'Feature': feature_name,\n",
        "                                     'Pearson': cor_support,\n",
        "                                     'Chi-2': chi_support,\n",
        "                                     'RFE': rfe_support,\n",
        "                                     'Logistic regression': embedded_lr_support,\n",
        "                                     'Random Forest': embedded_rf_support})\n",
        "\n",
        "feature_selection_df['Total'] = np.sum(feature_selection_df, axis = 1)\n",
        "feature_selection_df = feature_selection_df.sort_values(['Total', 'Feature'], ascending = False)\n",
        "feature_selection_df.index = range(1, len(feature_selection_df) + 1)\n",
        "feature_selection_df[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5EtGU2lKauW"
      },
      "source": [
        "Now select the columns on which at least 'min_score' feature selection tools agreed to be relevant\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5fz6FBGKq2_"
      },
      "outputs": [],
      "source": [
        "min_score = 4\n",
        "\n",
        "features = []\n",
        "for row in feature_selection_df.itertuples():\n",
        "  if (row[-1] >= min_score):\n",
        "    features.append(row[1])\n",
        "\n",
        "features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VElC7tM0LxJv"
      },
      "source": [
        "# Machine Learning models training\n",
        "\n",
        "We will split training and test sets by using a threshold (typically 0.3 for test, 0.7 for training data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAWUU_yTJ-rS"
      },
      "source": [
        "## Training and test set splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1rEfd-3L9LN"
      },
      "outputs": [],
      "source": [
        "train_set, test_set = train_test_split(data, test_size = 0.3, random_state = 42)\n",
        "\n",
        "y_train = train_set[class_column]\n",
        "x_train = train_set[features]\n",
        "\n",
        "y_test = test_set[class_column]\n",
        "x_test = test_set[features]\n",
        "print(len(train_set), \"train, \", len(test_set), \"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEVuSWAWMFRU"
      },
      "source": [
        "# ML Training\n",
        "\n",
        "## Random Forest Classifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this vector will store all of the models' accuracies\n",
        "accuracies = []"
      ],
      "metadata": {
        "id": "xzo_33TjE7iW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_fit = RandomForestClassifier(n_estimators = 8, criterion = \"gini\", min_samples_split = 2, bootstrap = True,\n",
        "                                max_features = 'auto', random_state = 42, min_samples_leaf = 1)\n",
        "rf = rf_fit.fit(x_train, y_train)\n",
        "rf_fit_pred = rf.predict(x_test)\n",
        "acc = accuracy_score(y_test, rf_fit_pred)\n",
        "accuracies.append(acc)"
      ],
      "metadata": {
        "id": "kuNSrAFcDJbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iSejPNhMcxp"
      },
      "outputs": [],
      "source": [
        "# optionally print the confusion matrix\n",
        "print (\"Random Forest - Test Confusion Matrix\\n\\n\", pd.crosstab(y_test, rf_fit_pred, rownames = [\"Actual\"],colnames = [\"Predicted\"]))\n",
        "print (\"\\nRandom Forest - Test accuracy\", round(acc, 3))\n",
        "print (\"\\nRandom Forest - Test Classification Report\\n\", classification_report(y_test, rf_fit_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JuGr_o5MbUe"
      },
      "source": [
        "## Logistic Regression\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8liWNbvML-a"
      },
      "outputs": [],
      "source": [
        "lr = LogisticRegression()\n",
        "lr = lr.fit(x_train, y_train)\n",
        "lr_pred = lr.predict(x_test)\n",
        "acc = accuracy_score(y_test, lr_pred)\n",
        "accuracies.append(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6x4jdSfMRLN"
      },
      "outputs": [],
      "source": [
        "# optionally print the confusion matrix\n",
        "print (\"Logistic Regression - Test Confusion Matrix\\n\\n\", pd.crosstab(y_test, lr_pred, rownames = [\"Actual\"],colnames = [\"Predicted\"]))\n",
        "print (\"\\n Test accuracy\", round(acc, 3))\n",
        "print (\"\\n Test Classification Report\\n\", classification_report(y_test, lr_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDfQqfttMs--"
      },
      "source": [
        "## KNN K-Nearest Neighbors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pinDfV68Mw0J"
      },
      "outputs": [],
      "source": [
        "def best_k(k):\n",
        "\n",
        "    best_acc = 0.0\n",
        "    K = None\n",
        "\n",
        "    for i in k:\n",
        "        knn_fit = KNeighborsClassifier(n_neighbors = i)\n",
        "        knn = knn_fit.fit(x_train, y_train)\n",
        "        knn_pred = knn1.predict(x_test)\n",
        "        acc = round(accuracy_score(y_test, knn_pred), 3)\n",
        "        if acc > best_acc:\n",
        "            K = i\n",
        "            print('Best K:', K, pd.crosstab(y_test, knn_pred, rownames = [\"Actual\"],colnames = [\"Predicted\"]))\n",
        "            best_acc = acc\n",
        "            print('\\nAccuracy:', best_acc)\n",
        "            print(classification_report(y_test, knn_pred))\n",
        "\n",
        "    best_model_knn = KNeighborsClassifier(n_neighbors = K)\n",
        "\n",
        "    accuracies.append(best_acc)\n",
        "    return best_model_knn\n",
        "\n",
        "k = [1,3]\n",
        "best_model_knn = best_k(k)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdX7Hiq4M71r"
      },
      "source": [
        "## SVM - Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yME-BZhM-eM"
      },
      "outputs": [],
      "source": [
        "param_distributions = {\"gamma\": reciprocal(0.001, 0.1), \"C\": uniform(1, 10)}\n",
        "rnd_search_cv = RandomizedSearchCV(SVC(), param_distributions, n_iter = 10, verbose = 2, cv = None, random_state = 42)\n",
        "rnd_search_cv = rnd_search_cv.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHWqSr5INO8M"
      },
      "outputs": [],
      "source": [
        "svclassifier = SVC(C = 1.2058449429580245, gamma = 0.0870602087830485, probability = True)\n",
        "svc = svclassifier.fit(x_train, y_train)\n",
        "y_pred = svc.predict(x_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "accuracies.append(acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optionally print confusion matrix\n",
        "print (\"SVM - Test Confusion Matrix\\n\\n\", pd.crosstab(y_test, y_pred, rownames = [\"Actual\"], colnames = [\"Predicted\"]))\n",
        "print (\"\\nSVM - Test accuracy\", round(acc, 3))\n",
        "print (\"\\nSVM - Test Classification Report\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "85CZ4ZFKFb-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc7MpzO8NUaA"
      },
      "source": [
        "## Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiPUYRiqNVwM"
      },
      "outputs": [],
      "source": [
        "dtree = DecisionTreeClassifier()\n",
        "dtc = dtree.fit(x_train, y_train)\n",
        "y_pred_dtree = dtc.predict(x_test)\n",
        "acc = accuracy_score(y_test, y_pred_dtree)\n",
        "accuracies.append(acc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optionally print confusion matrix\n",
        "print (\"Decision Tree - Test Confusion Matrix\\n\\n\", pd.crosstab(y_test, y_pred_dtree, rownames = [\"Actual\"],colnames = [\"Predicted\"]))\n",
        "print (\"\\nDecision Tree - Test accuracy\", round(acc, 3))\n",
        "print (\"\\nDecision Tree - Test Classification Report\\n\", classification_report(y_test, y_pred_dtree))"
      ],
      "metadata": {
        "id": "4ouCqr0sFn9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3OWEICqNbZL"
      },
      "source": [
        "## Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUfbJ70Ev506"
      },
      "outputs": [],
      "source": [
        "models = {\"Random Forest\" : rf_fit,\n",
        "          \"Logistic Regression\" : lr,\n",
        "          \"KNN\" : best_model_knn,\n",
        "          \"SVM\" : svclassifier,\n",
        "          \"Decision Tree\" : dtree}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMEilEHwFRd4"
      },
      "source": [
        "# ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EEYOyLBg4XoM"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = [12, 8]\n",
        "\n",
        "# Instantiate the classfiers and make a list\n",
        "classifiers = [rf_fit, lr, best_model_knn, svclassifier, dtree]\n",
        "\n",
        "# Define a result table as a DataFrame\n",
        "result_table = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n",
        "\n",
        "# Train the models and record the results\n",
        "for cls in classifiers:\n",
        "  model = cls.fit(x_train, y_train)\n",
        "  yproba = model.predict(x_test)\n",
        "  fpr, tpr, _ = roc_curve(y_test,  yproba)\n",
        "  auc = roc_auc_score(y_test, yproba)\n",
        "  result_table1 = result_table.append({'classifiers':cls.__class__.__name__,\n",
        "                                        'fpr':fpr,\n",
        "                                        'tpr':tpr,\n",
        "                                        'auc':auc}, ignore_index=True)\n",
        "\n",
        "# Set name of the classifiers as index labels\n",
        "result_table.set_index('classifiers', inplace=True)\n",
        "\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "\n",
        "for i in result_table.index:\n",
        "    plt.plot(result_table.loc[i]['fpr'],\n",
        "             result_table.loc[i]['tpr'],\n",
        "             label=\"{}, AUC={:.3f}\".format(i, result_table.loc[i]['auc']))\n",
        "\n",
        "plt.plot([0,1], [0,1], color='orange', linestyle='--')\n",
        "\n",
        "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
        "\n",
        "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
        "\n",
        "plt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\n",
        "plt.legend(prop={'size':13}, loc='lower right')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voting\n",
        "\n",
        "We will use soft voting (i.e. weighting ML models by their accuracies) and hard voting (i.e. majority of according models)"
      ],
      "metadata": {
        "id": "SMwiWLtlBUCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# define validation dataset\n",
        "validation_data = ..."
      ],
      "metadata": {
        "id": "mfvV6-dKebwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# soft voting\n",
        "s_voting = VotingClassifier(estimators=[('Rf', rf_fit),\n",
        "                                        ('Lr', lr),\n",
        "                                        ('Knn', best_model_knn),\n",
        "                                        ('Svc', svclassifier),\n",
        "                                        ('Dtc', dtree)],\n",
        "                            voting='soft',\n",
        "                            weights=accuracies)\n",
        "s_voting = s_voting.fit(data, Y)\n",
        "soft_voting = s_voting.predict(validation_data)"
      ],
      "metadata": {
        "id": "XY4nxW5SegUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hard voting\n",
        "h_voting = VotingClassifier( estimators=[ ('Rf', rf_fit),\n",
        "                                          ('Lr', lr),\n",
        "                                          ('Knn', best_model_knn),\n",
        "                                          ('Svc', svclassifier),\n",
        "                                          ('Dtc', dtree)],\n",
        "                             voting='hard')\n",
        "h_voting = h_voting.fit(data, Y)\n",
        "hard_voting = h_voting.predict(validation_data)"
      ],
      "metadata": {
        "id": "F09GyNnCgGd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Voting tables\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eXFgSXK_Ccqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tab_voting = pd.concat([X, soft_voting, hard_voting], axis = 1)\n",
        "tab_voting"
      ],
      "metadata": {
        "id": "QhRY39WngY3Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}